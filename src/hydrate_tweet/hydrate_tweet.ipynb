{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this once to set up\n",
    "\n",
    "from IPython.display import clear_output\n",
    "%pip install twarc\n",
    "%pip install --upgrade tweepy==3.8.0\n",
    "%pip install argparse\n",
    "%pip install xtract\n",
    "%pip install wget\n",
    "%pip install ipywidgets\n",
    "%pip install --upgrade emoji==1.7\n",
    "%pip install --upgrade emot==2.1\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "import os\n",
    "import wget\n",
    "import csv\n",
    "import linecache\n",
    "from shutil import copyfile\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import tweepy\n",
    "import datetime\n",
    "import random\n",
    "from twarc import Twarc2, expansions\n",
    "from tweepy import OAuthHandler\n",
    "from os.path import exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use your Twitter Developer keys and tokens ###\n",
    "### Must use Twitter API v1.1 (Elevated Access of Twitter Developer Account) ### \n",
    "\n",
    "CONSUMER_KEY = \"\" \n",
    "CONSUMER_SECRET_KEY = \"\"\n",
    "ACCESS_TOKEN_KEY = \"\"\n",
    "ACCESS_TOKEN_SECRET_KEY = \"\"\n",
    "\n",
    "#Creates a JSON Files with the API credentials\n",
    "with open('api_keys.json', 'w') as outfile:\n",
    "    json.dump({\n",
    "    \"consumer_key\":CONSUMER_KEY,\n",
    "    \"consumer_secret\":CONSUMER_SECRET_KEY,\n",
    "    \"access_token\":ACCESS_TOKEN_KEY,\n",
    "    \"access_token_secret\": ACCESS_TOKEN_SECRET_KEY\n",
    "     }, outfile)\n",
    "\n",
    "# The lines below are just to test if the twitter credentials are correct\n",
    "# Authenticate\n",
    "auth = tweepy.AppAuthHandler(CONSUMER_KEY, CONSUMER_SECRET_KEY)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "if (not api):\n",
    "    print (\"Can't Authenticate\")\n",
    "#  sys.exit(-1)\n",
    "else:\n",
    "    print('Authentication OK')\n",
    "\n",
    "# datasets that can be retrieved are from 07/26/2020 to 11/19/2022\n",
    "dataset_date = datetime.date(2020,7,26)\n",
    "dataset_end_date = datetime.date(2022,11,19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while dataset_date < dataset_end_date:\n",
    "    dataset_date_str = str(dataset_date)\n",
    "    dataset_date += datetime.timedelta(days=1)\n",
    "    # choose a dataset type: clean dataset or original dataset\n",
    "    # dataset_type = \"-dataset.tsv.gz\"\n",
    "    dataset_type = \"_clean-dataset.tsv.gz\"\n",
    "    dataset_URL = \"https://github.com/thepanacealab/covid19_twitter/blob/master/dailies/\" + dataset_date_str + \"/\" + dataset_date_str + dataset_type + \"?raw=true\"\n",
    "\n",
    "    if exists(\"clean-dataset.tsv.gz\"):\n",
    "        os.unlink(\"clean-dataset.tsv.gz\")\n",
    "\n",
    "    #Downloads the dataset (compressed in a GZ format)\n",
    "    wget.download(dataset_URL, out='clean-dataset.tsv.gz')\n",
    "    #Unzips the dataset and gets the TSV dataset\n",
    "    with gzip.open('clean-dataset.tsv.gz', 'rb') as f_in:\n",
    "        with open('clean-dataset.tsv', 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "    #Deletes the compressed GZ file\n",
    "    os.unlink(\"clean-dataset.tsv.gz\")\n",
    "\n",
    "    #Gets all possible languages from the dataset\n",
    "    df = pd.read_csv('clean-dataset.tsv',sep=\"\\t\")\n",
    "    lang_list = df.lang.unique()\n",
    "    lang_list= sorted(np.append(lang_list,'all'))\n",
    "    # pick language English\n",
    "    lang_picker = widgets.Dropdown(options=lang_list, value=\"en\")\n",
    "\n",
    "    #Creates a new clean dataset with the specified language (if specified)\n",
    "    filtered_language = lang_picker.value\n",
    "\n",
    "    #If language is specified, it will create another tsv file with the filtered records\n",
    "    filtered_tw = list()\n",
    "    current_line = 1\n",
    "    with open(\"clean-dataset.tsv\") as tsvfile:\n",
    "        tsvreader = csv.reader(tsvfile, delimiter=\"\\t\")\n",
    "\n",
    "        if current_line == 1:\n",
    "            filtered_tw.append(linecache.getline(\"clean-dataset.tsv\", current_line))\n",
    "\n",
    "            for line in tsvreader:\n",
    "                if line[3] == filtered_language:\n",
    "                    filtered_tw.append(linecache.getline(\"clean-dataset.tsv\", current_line))\n",
    "                current_line += 1\n",
    "\n",
    "    if exists(\"clean-dataset-filtered.tsv.gz\"):\n",
    "        os.unlink(\"clean-dataset-filtered.tsv.gz\")\n",
    "\n",
    "    with open('clean-dataset-filtered.tsv', 'w') as f_output:\n",
    "        for item in filtered_tw:\n",
    "            f_output.write(item)\n",
    "    linecache.clearcache()\n",
    "\n",
    "    !python get_metadata.py -i clean-dataset-filtered.tsv -o $dataset_date_str -k api_keys.json\n",
    "\n",
    "    # hydrated_tweets is a text file storing hydrated tweets (including unnecessary information)\n",
    "  \n",
    "    linecache.clearcache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of sample to be selected from the dataset\n",
    "num_samples = \"1000\"\n",
    "list_tweets = None\n",
    "\n",
    "# Change the date of dataset here\n",
    "selected_date = datetime.date(2021,1,1)\n",
    "selected_date_str = selected_date + '_short.json'\n",
    "\n",
    "with open(selected_date_str, \"r\") as myfile:\n",
    "    list_tweets = list(myfile)\n",
    "\n",
    "if int(num_samples) > len(list_tweets):\n",
    "    num_samples = len(list_tweets)\n",
    "\n",
    "sample = random.sample(list_tweets, int(num_samples))\n",
    "\n",
    "selected_date_sample = selected_date + '_sample_data.json'\n",
    "file = open(\"selected_date_sample\", \"w\")\n",
    "for i in sample:\n",
    "  file.write(i)\n",
    "file.close() #This close() is important\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse json\n",
    "!python parse_json_lite.py sample_data.json p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "226fd49ad92284713e19c2db7cd6c01594e914f5219b0282dd0ddab86dde5273"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
